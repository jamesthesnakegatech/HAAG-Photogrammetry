#!/usr/bin/env python3
"""
3D Analysis Notebook for BlendedMVS + SuGaR Results
Run this as a Jupyter notebook or Python script
"""

import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import json
import pandas as pd
from typing import List, Dict
import plotly.graph_objects as go
import plotly.express as px


class ReconstructionAnalyzer:
    """Analyze 3D reconstruction results"""
    
    def __init__(self, dataset_dir: str = "."):
        self.dataset_dir = Path(dataset_dir)
        self.analysis_dir = self.dataset_dir / "analysis"
        self.output_dir = self.dataset_dir / "output"
        
    def load_analysis_results(self, scene_id: str) -> Dict:
        """Load analysis results for a scene"""
        analysis_file = self.analysis_dir / scene_id / "analysis_results.json"
        if analysis_file.exists():
            with open(analysis_file, 'r') as f:
                return json.load(f)
        return None
        
    def create_quality_dashboard(self, scene_ids: List[str]):
        """Create a quality dashboard for multiple scenes"""
        data = []
        
        for scene_id in scene_ids:
            results = self.load_analysis_results(scene_id)
            if results and "mesh_analysis" in results:
                mesh = results["mesh_analysis"]
                if "error" not in mesh:
                    data.append({
                        "scene": scene_id,
                        "vertices": mesh["vertices"],
                        "faces": mesh["faces"],
                        "surface_area": mesh["surface_area"],
                        "watertight": mesh["watertight"]
                    })
                    
        if not data:
            print("No data available for dashboard")
            return
            
        df = pd.DataFrame(data)
        
        # Create subplots
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle('3D Reconstruction Quality Dashboard', fontsize=16)
        
        # Vertices count
        axes[0, 0].bar(df['scene'], df['vertices'])
        axes[0, 0].set_title('Vertex Count by Scene')
        axes[0, 0].set_xlabel('Scene')
        axes[0, 0].set_ylabel('Number of Vertices')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # Faces count
        axes[0, 1].bar(df['scene'], df['faces'])
        axes[0, 1].set_title('Face Count by Scene')
        axes[0, 1].set_xlabel('Scene')
        axes[0, 1].set_ylabel('Number of Faces')
        axes[0, 1].tick_params(axis='x', rotation=45)
        
        # Surface area
        axes[1, 0].bar(df['scene'], df['surface_area'])
        axes[1, 0].set_title('Surface Area by Scene')
        axes[1, 0].set_xlabel('Scene')
        axes[1, 0].set_ylabel('Surface Area')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        # Watertight status
        watertight_counts = df['watertight'].value_counts()
        axes[1, 1].pie(watertight_counts.values, labels=['Watertight', 'Not Watertight'], 
                       autopct='%1.1f%%')
        axes[1, 1].set_title('Watertight Mesh Distribution')
        
        plt.tight_layout()
        plt.savefig(self.analysis_dir / 'quality_dashboard.png', dpi=300)
        plt.show()
        
    def analyze_gaussian_distribution(self, scene_id: str):
        """Analyze Gaussian distribution in 3D space"""
        try:
            from plyfile import PlyData
            
            # Find PLY file
            ply_files = list((self.output_dir / scene_id / "sugar_output" / "gaussians").glob("*.ply"))
            if not ply_files:
                print(f"No PLY file found for {scene_id}")
                return
                
            ply = PlyData.read(ply_files[0])
            vertex = ply['vertex']
            
            # Extract positions
            x = vertex['x']
            y = vertex['y']
            z = vertex['z']
            
            # Create 3D scatter plot
            fig = go.Figure(data=[go.Scatter3d(
                x=x[::100],  # Sample every 100th point for performance
                y=y[::100],
                z=z[::100],
                mode='markers',
                marker=dict(
                    size=2,
                    color=z[::100],
                    colorscale='Viridis',
                    opacity=0.8
                )
            )])
            
            fig.update_layout(
                title=f'Gaussian Distribution for {scene_id}',
                scene=dict(
                    xaxis_title='X',
                    yaxis_title='Y',
                    zaxis_title='Z'
                )
            )
            
            fig.write_html(self.analysis_dir / f'{scene_id}_gaussian_distribution.html')
            fig.show()
            
            # Create density heatmap
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
            
            # XY projection
            axes[0].hexbin(x, y, gridsize=50, cmap='hot')
            axes[0].set_title('XY Projection')
            axes[0].set_xlabel('X')
            axes[0].set_ylabel('Y')
            
            # XZ projection
            axes[1].hexbin(x, z, gridsize=50, cmap='hot')
            axes[1].set_title('XZ Projection')
            axes[1].set_xlabel('X')
            axes[1].set_ylabel('Z')
            
            # YZ projection
            axes[2].hexbin(y, z, gridsize=50, cmap='hot')
            axes[2].set_title('YZ Projection')
            axes[2].set_xlabel('Y')
            axes[2].set_ylabel('Z')
            
            plt.suptitle(f'Gaussian Density Projections for {scene_id}')
            plt.tight_layout()
            plt.savefig(self.analysis_dir / f'{scene_id}_density_projections.png', dpi=300)
            plt.show()
            
        except ImportError:
            print("Please install required packages: pip install plyfile plotly")
            
    def compare_with_ground_truth_visual(self, scene_id: str):
        """Visual comparison with ground truth"""
        results = self.load_analysis_results(scene_id)
        if not results or "comparison" not in results:
            print(f"No comparison data for {scene_id}")
            return
            
        comp = results["comparison"]
        if "error" in comp:
            print(f"Comparison error: {comp['error']}")
            return
            
        # Create comparison visualization
        metrics = ['vertex_count_ratio', 'face_count_ratio']
        if 'hausdorff_distance' in comp:
            metrics.append('hausdorff_distance')
            
        values = [comp.get(m, 0) for m in metrics]
        
        fig, ax = plt.subplots(figsize=(10, 6))
        bars = ax.bar(metrics, values)
        
        # Color bars based on quality
        for i, (metric, value) in enumerate(zip(metrics, values)):
            if metric.endswith('_ratio'):
                # Ratio should be close to 1
                quality = 1 - abs(1 - value)
                color = plt.cm.RdYlGn(quality)
            else:
                # Lower distance is better
                quality = 1 / (1 + value)
                color = plt.cm.RdYlGn(quality)
            bars[i].set_color(color)
            
        ax.set_title(f'Ground Truth Comparison for {scene_id}')
        ax.set_ylabel('Value')
        ax.axhline(y=1, color='k', linestyle='--', alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(self.analysis_dir / f'{scene_id}_gt_comparison.png', dpi=300)
        plt.show()
        
    def generate_batch_report(self, scene_ids: List[str]):
        """Generate a comprehensive batch analysis report"""
        report = ["# Batch Analysis Report\n"]
        summary_data = []
        
        for scene_id in scene_ids:
            results = self.load_analysis_results(scene_id)
            if not results:
                continue
                
            scene_summary = {"scene_id": scene_id}
            
            # Extract key metrics
            if "mesh_analysis" in results and "error" not in results["mesh_analysis"]:
                mesh = results["mesh_analysis"]
                scene_summary.update({
                    "vertices": mesh["vertices"],
                    "faces": mesh["faces"],
                    "watertight": mesh["watertight"],
                    "surface_area": mesh["surface_area"]
                })
                
            if "gaussian_analysis" in results and "error" not in results["gaussian_analysis"]:
                gauss = results["gaussian_analysis"]
                scene_summary["num_gaussians"] = gauss["num_gaussians"]
                
            if "comparison" in results and "error" not in results["comparison"]:
                comp = results["comparison"]
                if "hausdorff_distance" in comp:
                    scene_summary["hausdorff_distance"] = comp["hausdorff_distance"]
                    
            summary_data.append(scene_summary)
            
        # Create summary DataFrame
        df = pd.DataFrame(summary_data)
        
        # Statistics
        report.append("## Summary Statistics\n")
        report.append(f"- Total scenes analyzed: {len(df)}")
        report.append(f"- Average vertices: {df['vertices'].mean():,.0f}")
        report.append(f"- Average faces: {df['faces'].mean():,.0f}")
        report.append(f"- Watertight meshes: {df['watertight'].sum()}/{len(df)}")
        
        if 'hausdorff_distance' in df.columns:
            report.append(f"- Average Hausdorff distance: {df['hausdorff_distance'].mean():.4f}")
            
        report.append("\n## Per-Scene Results\n")
        report.append(df.to_markdown(index=False))
        
        # Save report
        with open(self.analysis_dir / "batch_analysis_report.md", 'w') as f:
            f.write('\n'.join(report))
            
        print(f"âœ… Batch report saved to {self.analysis_dir / 'batch_analysis_report.md'}")
        
        # Create summary plots
        self.create_quality_dashboard(scene_ids)
        
        return df


# Example usage functions
def analyze_single_scene(scene_id: str, dataset_dir: str = "."):
    """Analyze a single scene"""
    analyzer = ReconstructionAnalyzer(dataset_dir)
    
    print(f"ðŸ“Š Analyzing {scene_id}...")
    
    # Load and display results
    results = analyzer.load_analysis_results(scene_id)
    if results:
        print(json.dumps(results, indent=2))
        
    # Visualize Gaussian distribution
    analyzer.analyze_gaussian_distribution(scene_id)
    
    # Compare with ground truth
    analyzer.compare_with_ground_truth_visual(scene_id)
    

def analyze_batch(list_file: str, dataset_dir: str = "."):
    """Analyze multiple scenes"""
    analyzer = ReconstructionAnalyzer(dataset_dir)
    
    # Read scene list
    with open(list_file, 'r') as f:
        scene_ids = [line.strip() for line in f if line.strip()]
        
    print(f"ðŸ“Š Analyzing {len(scene_ids)} scenes...")
    
    # Generate batch report
    df = analyzer.generate_batch_report(scene_ids)
    
    return df


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--batch" and len(sys.argv) > 2:
            analyze_batch(sys.argv[2])
        else:
            analyze_single_scene(sys.argv[1])
    else:
        print("Usage:")
        print("  python analysis_notebook.py <scene_id>")
        print("  python analysis_notebook.py --batch <list_file>")
